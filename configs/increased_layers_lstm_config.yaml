model: 'LSTM'

embed_size: 100

hidden_size: 100

num_layers: 2

epochs: 10

patience: 3

seq_len: 16

learning_rate: 0.001

log_interval: 5

batch_size: 64

save_path: "models"
