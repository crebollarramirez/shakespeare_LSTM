model: 'LSTM'

embed_size: 25

hidden_size: 150

num_layers: 2

epochs: 10

patience: 3

seq_len: 128

learning_rate: 0.001

log_interval: 5

batch_size: 64

save_path: "models"
